{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_angle(point1, point2, point3):\n",
    "    vector1 = (point1[0] - point2[0], point1[1] - point2[1])\n",
    "    vector2 = (point3[0] - point2[0], point3[1] - point2[1])\n",
    "\n",
    "\n",
    "    dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]\n",
    "    magnitude1 = math.sqrt(vector1[0] ** 2 + vector1[1] ** 2)\n",
    "    magnitude2 = math.sqrt(vector2[0] ** 2 + vector2[1] ** 2)\n",
    "\n",
    "    cosine_theta = dot_product / (magnitude1 * magnitude2)\n",
    "    theta = math.acos(cosine_theta)\n",
    "\n",
    "    angle_degrees = math.degrees(theta)\n",
    "\n",
    "    return angle_degrees\n",
    "\n",
    "\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "qiyam_data = []\n",
    "hip_threshold = 160\n",
    "knee_threshold = 160\n",
    "\n",
    "video_directory = 'C:/Users/syedn/OneDrive/Desktop/Islah.AI-FinalYearProject-ComputerVision/Qiyam_Videos'\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if video_file.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(frame_rgb)\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                \n",
    "                    shoulder = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_SHOULDER]\n",
    "                    hip = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_HIP]\n",
    "                    knee = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_KNEE]\n",
    "                    ankle = results.pose_landmarks.landmark[mp_pose.PoseLandmark.LEFT_ANKLE]\n",
    "\n",
    "                    shoulder_hip_angle = calculate_angle((shoulder.x, shoulder.y), (hip.x, hip.y), (ankle.x, ankle.y))\n",
    "                    hip_knee_angle = calculate_angle((hip.x, hip.y), (knee.x, knee.y), (ankle.x, ankle.y))\n",
    "\n",
    "                    \n",
    "                    shoulder_hip_label = 'correct' if shoulder_hip_angle > hip_threshold else 'incorrect'\n",
    "                    hip_knee_label = 'correct' if hip_knee_angle > knee_threshold else 'incorrect'\n",
    "\n",
    "                    qiyam_data.append([shoulder_hip_angle, hip_knee_angle, shoulder_hip_label, hip_knee_label])\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27: \n",
    "                    break\n",
    "\n",
    "    \n",
    "            cap.release()\n",
    "\n",
    "\n",
    "qiyam_df = pd.DataFrame(qiyam_data, columns=['Shoulder_Hip_Angle', 'Hip_Knee_Angle', 'Shoulder_Hip_Label', 'Hip_Knee_Label'])\n",
    "qiyam_df.to_csv('qiyam_dataset.csv', index=False)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
