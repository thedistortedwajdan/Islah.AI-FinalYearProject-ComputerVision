{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(center_landmark, start_landmark, end_landmark):\n",
    "\n",
    "    center = np.array(center_landmark)\n",
    "    start = np.array(start_landmark)\n",
    "    end = np.array(end_landmark)\n",
    "    \n",
    "\n",
    "    vector1 = start - center\n",
    "    vector2 = end - center\n",
    "    \n",
    "\n",
    "    angle_radians = np.arccos(np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2)))\n",
    "    \n",
    "\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "    \n",
    "    return angle_degrees\n",
    "\n",
    "\n",
    "def draw_selected_landmarks_on_image(rgb_image, landmarks, selected_landmarks, connections,labels):\n",
    "\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "\n",
    "\n",
    "    for index in selected_landmarks:\n",
    "        landmark = landmarks.landmark[index]\n",
    "        x, y, z = landmark.x, landmark.y, landmark.z\n",
    "\n",
    "        x_pixel, y_pixel = int(x * annotated_image.shape[1]), int(y * annotated_image.shape[0])\n",
    "        if(( (index in [28,24,26]))or( (index in [12,24,28]))):\n",
    "            cv2.circle(annotated_image, (x_pixel, y_pixel), radius=5, color=(0, 255, 0), thickness=-1)\n",
    "        else:\n",
    "            cv2.circle(annotated_image, (x_pixel, y_pixel), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "    for connection in connections:\n",
    "        start_index, end_index = connection\n",
    "        start_landmark = landmarks.landmark[start_index]\n",
    "        end_landmark = landmarks.landmark[end_index]\n",
    "        start_x, start_y = int(start_landmark.x * annotated_image.shape[1]), int(start_landmark.y * annotated_image.shape[0])\n",
    "        end_x, end_y = int(end_landmark.x * annotated_image.shape[1]), int(end_landmark.y * annotated_image.shape[0])\n",
    "        # cv2.line(annotated_image, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "        # if(label):\n",
    "        #     cv2.line(annotated_image, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "        # else:\n",
    "        #     cv2.line(annotated_image, (start_x, start_y), (end_x, end_y), (0, 0, 255), 2)\n",
    "        if((labels[0] and ((start_index==24 and end_index==26) or (start_index==26 and end_index==24) or (start_index==26 and end_index==28) or (start_index==28 and end_index==26) )) or (labels[1] and ((start_index==12 and end_index==24) or (start_index==24 and end_index==12) or (start_index==24 and end_index==28) or (start_index==28 and end_index==24) )) ):\n",
    "            cv2.line(annotated_image, (start_x, start_y), (end_x, end_y), (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.line(annotated_image, (start_x, start_y), (end_x, end_y), (0, 0, 255), 2)\n",
    "            \n",
    "\n",
    "    return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "qiyam_data = []\n",
    "hip_threshold = 160\n",
    "knee_threshold = 160\n",
    "selected_landmarks_indices = [16,14,12,24,26,28,32]\n",
    "selected_landmarks_connections = [(16,14),(14,12),(24,26),(26,28),(12,24),(24,28),(28,32)]\n",
    "\n",
    "video_directory = 'videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, model_complexity=1) as pose:\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if video_file.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(video_directory, video_file)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(frame_rgb)\n",
    "\n",
    "                if results.pose_landmarks:\n",
    "                     landmark_12 = (results.pose_landmarks.landmark[selected_landmarks_indices[2]].x,\n",
    "                                    results.pose_landmarks.landmark[selected_landmarks_indices[2]].y)\n",
    "                     landmark_24 = (results.pose_landmarks.landmark[selected_landmarks_indices[3]].x,\n",
    "                                    results.pose_landmarks.landmark[selected_landmarks_indices[3]].y)\n",
    "                     landmark_26 = (results.pose_landmarks.landmark[selected_landmarks_indices[4]].x,\n",
    "                                    results.pose_landmarks.landmark[selected_landmarks_indices[4]].y)\n",
    "                     \n",
    "                     hip_angle = calculate_angle(landmark_24, landmark_12, landmark_26)\n",
    "                     annotated_frame= draw_selected_landmarks_on_image(frame, results.pose_landmarks, selected_landmarks_indices, selected_landmarks_connections)\n",
    "\n",
    "                    \n",
    "                    # shoulder_hip_label = 'correct' if shoulder_hip_angle > hip_threshold else 'incorrect'\n",
    "                    # hip_knee_label = 'correct' if hip_knee_angle > knee_threshold else 'incorrect'\n",
    "\n",
    "                    # qiyam_data.append([shoulder_hip_angle, hip_knee_angle, shoulder_hip_label, hip_knee_label])\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == 27: \n",
    "                    break\n",
    "\n",
    "    \n",
    "            cap.release()\n",
    "\n",
    "\n",
    "# qiyam_df = pd.DataFrame(qiyam_data, columns=['Shoulder_Hip_Angle', 'Hip_Knee_Angle', 'Shoulder_Hip_Label', 'Hip_Knee_Label'])\n",
    "# qiyam_df.to_csv('qiyam_dataset.csv', index=False)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
